{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5alEWzZoLeIr",
        "outputId": "b25ebfb9-6c22-4a15-804c-a853acc339a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Zero-DCE_extension'...\n",
            "remote: Enumerating objects: 2140, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 2140 (delta 0), reused 2 (delta 0), pack-reused 2136 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2140/2140), 100.92 MiB | 27.67 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Li-Chongyi/Zero-DCE_extension.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pytorch\n",
        "!pip install opencv\n",
        "!pip install torchvision\n",
        "!pip install cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5GzUtIKLm3g",
        "outputId": "e6fc9c47-9783-4933-c54e-dfa2ecd21abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for Pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for Pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for Pytorch\n",
            "Failed to build Pytorch\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (Pytorch)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.8.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->torchvision) (3.0.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cuda (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cuda\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import glob\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "sys.path.append(os.path.abspath(\"/content/Zero-DCE_extension/Zero-DCE++\"))\n",
        "import model as zdce_model\n",
        "\n",
        "\n",
        "def load_model(weight_path: str, scale_factor: int = 12, device: str = None):\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    net = zdce_model.enhance_net_nopool(scale_factor).to(device)\n",
        "    state = torch.load(weight_path, map_location=device)\n",
        "    net.load_state_dict(state)\n",
        "    net.eval()\n",
        "    print(f\"Model loaded to {device} from {weight_path}\")\n",
        "    return net, device\n",
        "\n",
        "\n",
        "def _crop_to_multiple(img_np: np.ndarray, factor: int):\n",
        "    h, w = img_np.shape[:2]\n",
        "    h2 = (h // factor) * factor\n",
        "    w2 = (w // factor) * factor\n",
        "    if h2 == h and w2 == w:\n",
        "        return img_np\n",
        "    return img_np[0:h2, 0:w2, :]\n",
        "\n",
        "\n",
        "def _tensor_to_bgr_uint8(tensor: torch.Tensor):\n",
        "    if tensor.dim() == 4 and tensor.shape[0] == 1:\n",
        "        tensor = tensor[0]\n",
        "    t = tensor.detach().cpu().clamp(0.0, 1.0)\n",
        "    arr = (t.numpy().transpose(1, 2, 0) * 255.0).astype(np.uint8)\n",
        "    bgr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
        "    return bgr\n",
        "\n",
        "\n",
        "def enhance_video(\n",
        "    input_video_path: str,\n",
        "    output_video_path: str,\n",
        "    model_weights: str,\n",
        "    scale_factor: int = 12,\n",
        "    sample_every_n: int = 1,\n",
        "    codec: str = \"mp4v\",\n",
        "    max_frames: int | None = None,\n",
        "):\n",
        "    model, device = load_model(model_weights, scale_factor=scale_factor)\n",
        "\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Cannot open input video: {input_video_path}\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
        "    orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
        "\n",
        "    cropped_h = (orig_h // scale_factor) * scale_factor\n",
        "    cropped_w = (orig_w // scale_factor) * scale_factor\n",
        "    if cropped_h == 0 or cropped_w == 0:\n",
        "        raise RuntimeError(\"Video resolution too small for the chosen scale_factor.\")\n",
        "\n",
        "    out_dir = os.path.dirname(output_video_path)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (cropped_w, cropped_h))\n",
        "\n",
        "    frame_idx = 0\n",
        "    processed = 0\n",
        "    total_time = 0.0\n",
        "\n",
        "    print(f\"Input video: {input_video_path} ({orig_w}x{orig_h}, fps={fps}, frames={total_frames})\")\n",
        "    print(f\"Output video: {output_video_path} ({cropped_w}x{cropped_h}), sample_every_n={sample_every_n}\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame_bgr = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if sample_every_n > 1 and (frame_idx % sample_every_n) != 0:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            if max_frames is not None and processed >= max_frames:\n",
        "                break\n",
        "\n",
        "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "            frame_rgb = _crop_to_multiple(frame_rgb, scale_factor)\n",
        "\n",
        "            img_np = frame_rgb.astype(np.float32) / 255.0\n",
        "            img_t = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).to(device)\n",
        "\n",
        "            start = time.time()\n",
        "            with torch.no_grad():\n",
        "                enhanced_tensor, *_ = model(img_t)\n",
        "            elapsed = time.time() - start\n",
        "            total_time += elapsed\n",
        "\n",
        "            out_frame = _tensor_to_bgr_uint8(enhanced_tensor)\n",
        "            if (out_frame.shape[1], out_frame.shape[0]) != (cropped_w, cropped_h):\n",
        "                out_frame = cv2.resize(out_frame, (cropped_w, cropped_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            out.write(out_frame)\n",
        "\n",
        "            processed += 1\n",
        "            frame_idx += 1\n",
        "            if processed % 50 == 0:\n",
        "                print(f\"Processed {processed} frames (frame_idx={frame_idx}) — last frame time {elapsed:.3f}s\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interrupted by user. Finalizing...\")\n",
        "\n",
        "    finally:\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "    print(f\"Done. Processed {processed} frames. Total inference time: {total_time:.4f}s\")\n",
        "    if processed:\n",
        "        print(f\"Average time/frame: {total_time / processed:.4f}s\")\n",
        "\n",
        "    return {\n",
        "        \"output_path\": output_video_path,\n",
        "        \"processed_frames\": processed,\n",
        "        \"total_inference_time\": total_time,\n",
        "        \"avg_time_per_frame\": (total_time / processed) if processed else 0.0,\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_video = \"/content/test/low_light_video.mp4\"\n",
        "    output_video = \"/content/results_Zero_DCE++/enhanced_video.mp4\"\n",
        "    weights = \"/content/Zero-DCE_extension/Zero-DCE++/snapshots_Zero_DCE++/Epoch99.pth\"\n",
        "\n",
        "    result = enhance_video(\n",
        "        input_video_path=input_video,\n",
        "        output_video_path=output_video,\n",
        "        model_weights=weights,\n",
        "        scale_factor=12,\n",
        "        sample_every_n=1,\n",
        "        codec=\"mp4v\",\n",
        "        max_frames=None,\n",
        "    )\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCwSUF1DMmkP",
        "outputId": "48801f74-d879-49f4-eadd-19bede8e837e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded to cuda from /content/Zero-DCE_extension/Zero-DCE++/snapshots_Zero_DCE++/Epoch99.pth\n",
            "Input video: /content/output_1.mp4 (1920x1080, fps=22.808764940239044, frames=229)\n",
            "Output video: /content/enhanced_video.mp4 (1920x1080), sample_every_n=1\n",
            "Processed 50 frames (frame_idx=50) — last frame time 0.002s\n",
            "Processed 100 frames (frame_idx=100) — last frame time 0.002s\n",
            "Processed 150 frames (frame_idx=150) — last frame time 0.002s\n",
            "Processed 200 frames (frame_idx=200) — last frame time 0.002s\n",
            "Done. Processed 229 frames. Total inference time: 0.5645s\n",
            "Average time/frame: 0.0025s\n",
            "{'output_path': '/content/enhanced_video.mp4', 'processed_frames': 229, 'total_inference_time': 0.5644688606262207, 'avg_time_per_frame': 0.0024649295223852434}\n"
          ]
        }
      ]
    }
  ]
}